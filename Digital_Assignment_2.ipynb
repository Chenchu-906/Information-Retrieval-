{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chenchu-906/Information-Retrieval-/blob/main/Digital_Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VECTOR SPACE MODEL \n",
        "\n",
        "Names: \n",
        "\n",
        "Chenchu Aravind 20MIA1126\n",
        "\n",
        "Shiva Sindhu Perla 20MIA1104\n"
      ],
      "metadata": {
        "id": "YGxotwGmADyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Importing the libraries\"\"\"\n",
        "import glob\n",
        "import math\n",
        "import re\n",
        "import sys\n",
        "from collections import defaultdict\n",
        "from functools import reduce\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "STOPWORDS = set(stopwords.words(\"english\"))\n",
        "\n",
        "\"\"\"Importing the text documents\"\"\"\n",
        "CORPUS = \"/content/sample_data/*\"\n",
        "\n",
        "# Each document has an id, and these are the keys in the following dict.\n",
        "document_filenames = dict()\n",
        "\n",
        "# The size of the corpus\n",
        "N = 0\n",
        "# vocabulary: a set to contain all unique terms (i.e. words) in the corpus\n",
        "vocabulary = set()\n",
        "postings = defaultdict(dict)\n",
        "document_frequency = defaultdict(int)\n",
        "length = defaultdict(float)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTwI2LMk3D7A",
        "outputId": "cd14619f-65d6-44f1-8795-2e69fd3ff3aa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Get details about corpus\n",
        "    get_corpus()\n",
        "\n",
        "    # Initialise terms and postings for the corpus\n",
        "    initialize_terms_and_postings()\n",
        "    initialize_document_frequencies()\n",
        "    initialize_lengths()\n",
        "    while True:\n",
        "\n",
        "        # Gets the sorted list of ranked documents\n",
        "        scores = do_search()\n",
        "        print_scores(scores)"
      ],
      "metadata": {
        "id": "rpOpUtms3JNR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_corpus():\n",
        "    global document_filenames, N\n",
        "\n",
        "    # Fetch list of document names in corpus\n",
        "    documents = glob.glob(CORPUS)\n",
        "\n",
        "    # Set size of corpus\n",
        "    N = len(documents)\n",
        "\n",
        "    # Dictionary having doc id as key and document name as value\n",
        "    document_filenames = dict(zip(range(N), documents))"
      ],
      "metadata": {
        "id": "1_NgjAnr3Li-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_terms_and_postings():\n",
        "    \"\"\"Reads in each document in document_filenames, splits it into a\n",
        "    list of terms (i.e., tokenizes it).\"\"\"\n",
        "    global vocabulary, postings\n",
        "    for id in document_filenames:\n",
        "\n",
        "        # Read the document\n",
        "        with open(document_filenames[id], \"r\") as f:\n",
        "            document = f.read()\n",
        "\n",
        "        # Remove all special characters from the document\n",
        "        document = remove_special_characters(document)\n",
        "\n",
        "        # Remove digits from the document\n",
        "        document = remove_digits(document)\n",
        "\n",
        "        # Tokenize the document\n",
        "        terms = tokenize(document)\n",
        "\n",
        "        # Remove duplicates from the terms\n",
        "        unique_terms = set(terms)\n",
        "\n",
        "        # Add unique terms to the vocabulary\n",
        "        vocabulary = vocabulary.union(unique_terms)\n",
        "\n",
        "        # For every unique term\n",
        "        for term in unique_terms:\n",
        "\n",
        "            # The value is the frequency of the term in the document\n",
        "            postings[term][id] = terms.count(term)\n"
      ],
      "metadata": {
        "id": "u1GlS_583PPP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(document):\n",
        "    \"\"\"Returns a list whose elements are the separate terms in document\"\"\"\n",
        "    # Tokenize text into terms\n",
        "    terms = word_tokenize(document)\n",
        "    terms = [term.lower() for term in terms if term not in STOPWORDS] \n",
        "    return terms\n",
        "document='Every year Maha Shivratri is celebrated with a lot of pomp and grandeur.'\n",
        "print(tokenize(document))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAzcRz_q3RfL",
        "outputId": "f6e569c8-4a16-452f-aaa3-a56f1c4555fb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['every', 'year', 'maha', 'shivratri', 'celebrated', 'lot', 'pomp', 'grandeur', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print()"
      ],
      "metadata": {
        "id": "KTIIrOjS4b5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_document_frequencies():\n",
        "    \"\"\"For each term in the vocabulary, count the number of documents\n",
        "    it appears in, and store the value in document_frequncy[term]\n",
        "    \"\"\"\n",
        "    global document_frequency\n",
        "    for term in vocabulary:\n",
        "        document_frequency[term] = len(postings[term])\n"
      ],
      "metadata": {
        "id": "MS-3L1xQ3UXY"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_lengths():\n",
        "    \"\"\" Computes the length for each document \"\"\"\n",
        "    global length\n",
        "    for id in document_filenames:\n",
        "        l = 0\n",
        "        for term in vocabulary:\n",
        "            l += term_frequency(term, id) ** 2\n",
        "        length[id] = math.sqrt(l)"
      ],
      "metadata": {
        "id": "1M82zgfN3XhF"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def term_frequency(term, id):\n",
        "    \"\"\"Returns the term frequency of term in document id\"\"\"\n",
        "    if id in postings[term]:\n",
        "        return postings[term][id]\n",
        "    else:\n",
        "        return 0.0"
      ],
      "metadata": {
        "id": "bqLwVPvq3a06"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inverse_document_frequency(term):\n",
        "    \"\"\"Returns the inverse document frequency of term.\"\"\"\n",
        "    if term in vocabulary:\n",
        "        return math.log(N / document_frequency[term], 2)\n",
        "    else:\n",
        "        return 0.0\n",
        "print(inverse_document_frequency(23.3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2G8TUdf3fHX",
        "outputId": "4a208872-9326-4c8e-f1cd-7c0d7c678da7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_scores(scores):\n",
        "    print(\"Top 3 Documents based on Cosine similarity\")\n",
        "    print(\"-\" * 42)\n",
        "    print(\"| %s | %-30s |\" % (\"Score\", \"Document\"))\n",
        "    print(\"-\" * 42)\n",
        "\n",
        "    for (id, score) in scores:\n",
        "        if score != 0.0:\n",
        "            print(\"| %s | %-30s |\" % (str(score)[:5], document_filenames[id]))\n",
        "\n",
        "    print(\"-\" * 42, end=\"\\n\\n\")\n",
        "    print(\"Vocabulary of words:\",vocabulary)\n",
        "\n",
        "\n",
        "def do_search():\n",
        "    \"\"\"Gets the input from the user what they would like to search for, and returns a\n",
        "    list of relevant documents, in decreasing order of cosine similarity\n",
        "    \"\"\"\n",
        "    query = tokenize(input(\"Search query >> \"))\n",
        "\n",
        "    # Exit if query is empty\n",
        "    if query == []:\n",
        "        sys.exit()\n",
        "\n",
        "    scores = sorted(\n",
        "        [(id, similarity(query, id)) for id in range(N)],\n",
        "        key=lambda x: x[1],\n",
        "        reverse=True,\n",
        "    )\n",
        "\n",
        "    return scores\n",
        "\n",
        "\n",
        "def intersection(sets):\n",
        "    \"\"\"Returns the intersection of all sets in the list sets.\"\"\"\n",
        "    return reduce(set.intersection, [s for s in sets])\n"
      ],
      "metadata": {
        "id": "A8WZUH133mJc"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def similarity(query, id):\n",
        "    \"\"\"Returns the cosine similarity between query and document id.\"\"\"\n",
        "    similarity = 0.0\n",
        "\n",
        "    for term in query:\n",
        "\n",
        "        if term in vocabulary:\n",
        "\n",
        "            # For every term in query which is also in vocabulary,\n",
        "            # calculate tf-idf score of the term and add to similarity\n",
        "            similarity += term_frequency(term, id) * inverse_document_frequency(term)\n",
        "\n",
        "    similarity = similarity / length[id]\n",
        "\n",
        "    return similarity\n",
        "\n",
        "\n",
        "def remove_special_characters(text):\n",
        "    \"\"\" Removes special characters using regex substitution \"\"\"\n",
        "    regex = re.compile(r\"[^a-zA-Z0-9\\s]\")\n",
        "    return re.sub(regex, \"\", text)\n",
        "\n",
        "\n",
        "def remove_digits(text):\n",
        "    \"\"\" Removes digits using regex substitution \"\"\"\n",
        "    regex = re.compile(r\"\\d\")\n",
        "    return re.sub(regex, \"\", text)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "-k7WwvUx3pi6",
        "outputId": "193eb3d3-d5b8-44bf-a15c-c11e3a8ad3a5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Search query >> Maha Shivratri will be celebrated on February 18\n",
            "Top 3 Documents based on Cosine similarity\n",
            "------------------------------------------\n",
            "| Score | Document                       |\n",
            "------------------------------------------\n",
            "| 0.272 | /content/sample_data/Doc2.txt  |\n",
            "| 0.223 | /content/sample_data/Doc4.txt  |\n",
            "| 0.079 | /content/sample_data/Doc1.txt  |\n",
            "------------------------------------------\n",
            "\n",
            "Vocabulary of words: {'sdc', 'devotees', 'february', 'awake', 'dances', 'important', 'auspicious', 'glee', 'significance', 'prosperity', 'one', 'mantras', 'festival', 'millions', 'stay', 'maha', 'power', 'etc', 'grandness', 'fast', 'year', 'checnhu', 'holds', 'hope', 'protects', 'grandeur', 'keep', 'people', 'blessings', 'hindu', 'lot', 'happiness', 'beautiful', 'negative', 'lord', 'every', 'momentous', 'chants', 'powerful', 'india', 'occasion', 'night', 'pomp', 'since', 'festivals', 'spirits', 'shivratri', 'fervour', 'time', 'evil', 'considered', 'prayers', 'special', 'shiva', 'this', 'celebrated', 'folk', 'celebrates', 'pray', 'the', 'google', 'songs', 'energy', 'he', 'celebrate', 'aravind', 'accompanied', 'it', 'epitome'}\n",
            "Search query >> \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def term_frequency(term, id):\n",
        "    \"\"\"Returns the term frequency of term in document id.  \"\"\"\n",
        "    if id in postings[term]:\n",
        "        print(postings[term][id])\n",
        "    else:\n",
        "        return 0.0"
      ],
      "metadata": {
        "id": "mFnGz319z7Uk"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 = \"Every year Maha Shivratri is celebrated with a lot of pomp and grandeur. It is considered to be a very special time of the year since millions of people celebrate this momentous occasion with a lot of fervour and glee.\"\n",
        "doc2 = \"Lord Shiva devotees celebrate this occasion with a lot of grandness. It is accompanied by folk dances, songs, prayers, chants, mantras etc. This year, the beautiful occasion of Maha Shivratri will be celebrated on February 18.\"\n",
        "doc3 = \"People keep a fast on this Maha shivratri, stay awake at night and pray to the lord for blessings, happiness, hope and prosperity. This festival holds a lot of significance and is considered to be one of the most important festivals in India.\"\n",
        "doc4 = \"The festival of Maha Shivratri will be celebrated on February 18 and is a very auspicious festival. This Hindu festival celebrates the power of Lord Shiva. Lord Shiva protects his devotees from negative and evil spirits. He is the epitome of powerful and auspicious energy.\"\n",
        "     \n"
      ],
      "metadata": {
        "id": "AKznybSiz_Xy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Jaccard_Similarity(doc1, doc2): \n",
        "    # List the unique words in a document\n",
        "    words_doc1 = set(doc1.lower().split()) \n",
        "    words_doc2 = set(doc2.lower().split()) \n",
        "    # Find the intersection of words list of doc1 & doc2\n",
        "    intersection = words_doc1.intersection(words_doc2)\n",
        "    # Find the union of words list of doc1 & doc2\n",
        "    union = words_doc1.union(words_doc2)    \n",
        "    return float(len(intersection)) / len(union)"
      ],
      "metadata": {
        "id": "S1LnxjHK0Yuo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Jaccard_Similarity(doc1,doc2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6nwth1c0btD",
        "outputId": "47d4213c-ea2e-46c4-c27f-1e7aacfdf20b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2857142857142857"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Jaccard_Similarity(doc2,doc3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ouz19jhg0fUx",
        "outputId": "b178b78d-2407-4d30-8434-acc98b3a921c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1694915254237288"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Jaccard_Similarity(doc3,doc4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Osad7JOm0h9R",
        "outputId": "81dcb7c7-6074-4d98-b6b8-ccb74c14402f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18333333333333332"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w5CA0VL30mWm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1k6orf6ZpHYT8f0SFH_5k623PCl81otAq",
      "authorship_tag": "ABX9TyO1Fn/q+RLvd3ZKt3uSM+Rn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}